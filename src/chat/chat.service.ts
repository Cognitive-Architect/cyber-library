import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import { SearchService } from '../search/search.service';
import { ChatRequestDto } from './dto/chat-request.dto';

@Injectable()
export class ChatService {
  private openai: OpenAI;
  private readonly logger = new Logger(ChatService.name);
  private readonly apiKey: string | undefined;

  constructor(
    private readonly configService: ConfigService,
    private readonly searchService: SearchService, // ğŸ‘ˆ æ³¨å…¥æœç´¢æœåŠ¡
  ) {
    this.apiKey = this.configService.get<string>('OPENAI_API_KEY');
    if (this.apiKey) {
      this.openai = new OpenAI({ apiKey: this.apiKey });
    }
  }

  async chat(dto: ChatRequestDto) {
    const { message } = dto;

    // 1. å…ˆå»å›¾ä¹¦é¦†â€œæŸ¥èµ„æ–™â€ (RAG çš„ Retrieval éƒ¨åˆ†)
    // è¿™é‡Œçš„ k=3 æ„å‘³ç€æˆ‘ä»¬åªå–æœ€ç›¸å…³çš„ 3 ä¸ªç‰‡æ®µç»™ AI çœ‹
    const searchResults = await this.searchService.search({ 
      query: message, 
      k: 3, 
      // âŒ åˆ æ‰äº† threshold: 0.0ï¼Œå› ä¸º SearchService å·²ç»ä¸éœ€è¦å®ƒäº†
    });

    // 2. æŠŠæŸ¥åˆ°çš„èµ„æ–™æ‹¼æˆä¸€æ®µâ€œèƒŒæ™¯çŸ¥è¯†â€
    const context = searchResults.map(r => r.content).join('\n\n');

    // 3. æ„å»º Prompt (æç¤ºè¯)
    const systemPrompt = `
    ä½ æ˜¯ä¸€ä¸ªåŸºäºâ€œèµ›åšå›¾ä¹¦é¦†â€çŸ¥è¯†åº“çš„ AI åŠ©æ‰‹ã€‚
    è¯·æ ¹æ®ä¸‹é¢çš„ã€èƒŒæ™¯çŸ¥è¯†ã€‘æ¥å›ç­”ç”¨æˆ·çš„ã€é—®é¢˜ã€‘ã€‚
    å¦‚æœã€èƒŒæ™¯çŸ¥è¯†ã€‘é‡Œæ²¡æœ‰ç­”æ¡ˆï¼Œè¯·ç›´æ¥è¯´â€œæˆ‘ä¸çŸ¥é“â€ã€‚

    ã€èƒŒæ™¯çŸ¥è¯†ã€‘ï¼š
    ${context}
    `;

    // 4. è°ƒç”¨ AI (Generation éƒ¨åˆ†)
    if (!this.apiKey || process.env.MOCK_EMBEDDING === 'true') {
      // æ³¨æ„ï¼šè¿™é‡Œæˆ‘é¡ºæ‰‹å¸®æ‚¨è¡¥ä¸Šäº† sourcesï¼Œè¿™æ · Mock æ¨¡å¼ä¸‹ä¹Ÿèƒ½çœ‹åˆ°å¼•ç”¨æ¥æº
      return this.mockChatResponse(message, context, searchResults);
    }

    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo', // æˆ–è€… gpt-4
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: message },
        ],
      });
      return {
        answer: response.choices[0].message.content,
        sources: searchResults, // æŠŠå‚è€ƒæ¥æºä¹Ÿè¿”å›å»ï¼Œæ˜¾å¾—ä¸“ä¸š
      };
    } catch (error) {
      this.logger.error(`OpenAI Error: ${error.message}`);
      return { answer: 'AI å¤§è„‘çŸ­è·¯äº†ï¼Œè¯·ç¨åå†è¯•ã€‚', sources: [] };
    }
  }

  // ğŸ‘‡ å’±ä»¬çš„çœé’±æ›¿èº« (é¡ºä¾¿æŠŠ sources ä¹ŸåŠ ä¸Šäº†)
  private mockChatResponse(message: string, context: string, sources: any[]) {
    this.logger.log(`[Mock Chat] Context found: ${context.length} chars`);
    return {
      answer: `[Mock AI]: æˆ‘å·²æ”¶åˆ°æ‚¨çš„é—®é¢˜ï¼šâ€œ${message}â€ã€‚\næ ¹æ®æ£€ç´¢åˆ°çš„ ${context.length} å­—ç¬¦çš„èµ„æ–™ï¼ˆæç‹—è›‹...ï¼‰ï¼Œæˆ‘è®¤ä¸ºç­”æ¡ˆæ˜¯ï¼šæç‹—è›‹ç¡®å®åœ¨åšç©ºã€‚`,
      sources: sources, // âœ… ç°åœ¨è¿”å›çœŸå®çš„æœç´¢ç»“æœ
    };
  }
}